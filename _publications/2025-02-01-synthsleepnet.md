---
title: "Toward Foundational Model for Sleep Analysis Using a Multimodal Hybrid Self-Supervised Learning Framework"
collection: publications
category: manuscripts
permalink: /publication/2025-02-01-synthsleepnet
excerpt: 'SynthSleepNet: A multimodal hybrid self-supervised learning framework for analyzing polysomnography (PSG) data, combining masked prediction and contrastive learning.'
date: 2025-02-01
venue: 'IEEE Transactions on Cybernetics (TCYB)'
paperurl: 'https://arxiv.org/abs/2502.17481'
citation: 'Lee, C.-H., Kim, H., Yoon, B. C., & Kim, D.-J. (2025). "Toward Foundational Model for Sleep Analysis Using a Multimodal Hybrid Self-Supervised Learning Framework." <i>IEEE Transactions on Cybernetics</i>.'
---

This study proposes SynthSleepNet, a multimodal hybrid self-supervised learning (SSL) methodology for analyzing polysomnography (PSG) data. Drawing inspiration from NeuroNet and MultiMAE, SynthSleepNet introduces a novel multimodal SSL framework that combines masked prediction and contrastive learning to jointly exploit generative and discriminative representation learning.

SynthSleepNet integrates four modality-specific backbones learned from EEG, EOG, EMG, and ECG signals. The framework achieved superior performance compared to state-of-the-art methods across three downstream tasks: sleep-stage classification (89.89%), apnea detection (99.75%), and hypopnea detection (89.60%).

[GitHub Repository](https://github.com/dlcjfgmlnasa/SynthSleepNet)
